{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "covid-19-chest-x-ray-with-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1J0z-QZOwJp",
        "colab_type": "text"
      },
      "source": [
        "# Adversarial AttacksAnd Interpretability Covid Chestxray Dataset\n",
        "\n",
        "Final Project - Cognitive Computing and Artificial Intelligence - UniCT a.a 2019/2020\n",
        "\n",
        "*   Raiti Mario O55000434\n",
        "*   Sortino Renato O55000405\n",
        "*   Nardo Gabriele Salvatore O55000430"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfPtxK2G3_O0",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7cKl1Gs3_O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random, torch, time, copy\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "from skimage.filters import threshold_local\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19WANWB4O8IB",
        "colab_type": "text"
      },
      "source": [
        "## Enable Cuda for GPU computing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPkLsdkGO6ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup device\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u-mxoVP3_O4",
        "colab_type": "text"
      },
      "source": [
        "## Create paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "WXMBesMC3_O4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "538bb067-7c00-4bd3-906d-57968c62bcc0"
      },
      "source": [
        "# dataset_path = './dataset'\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "#covid_dataset_path = \"/content/drive/My Drive/Covid_Chestray_Dataset\"\n",
        "covid_dataset_path = \"/content/drive/.shortcut-targets-by-id/1jrhnTdvTCvooz8T_SbI3qAsDLr08pKrk/Covid_Chestray_Dataset/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4egPi9M3_O7",
        "colab_type": "text"
      },
      "source": [
        "## Creating a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu0t8sma3_O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['no-covid', 'covid']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNzIGndH3_O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class image_dataset(Dataset):\n",
        "    \"\"\"Class creator for the x-ray dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_path, root_dir, transform=None, phase=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        # If not a PA view, drop the line \n",
        "        self.df.drop(self.df[self.df.view != 'PA'].index, inplace=True)\n",
        "        self.phase = phase\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        if self.df['finding'].iloc[idx] != 'COVID-19':\n",
        "            finding = 0\n",
        "            img_path = os.path.sep.join([covid_dataset_path, 'images', self.df['filename'].iloc[idx]])\n",
        "            image = Image.open(img_path)\n",
        "            sample = {'image': image, 'finding': finding}\n",
        "            \n",
        "            if self.transform:\n",
        "                sample = {'image': self.transform[self.phase](sample['image']), 'finding': finding}\n",
        "\n",
        "        else:\n",
        "            finding = 1\n",
        "            img_path = os.path.sep.join([covid_dataset_path, 'images', self.df['filename'].iloc[idx]])\n",
        "            image = Image.open(img_path)\n",
        "            sample = {'image': image, 'finding': finding}\n",
        "\n",
        "            if self.transform:\n",
        "                sample = {'image': self.transform[self.phase](sample['image']), 'finding': finding}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijs1tlD93_PA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xray_dataset = image_dataset(csv_path=os.path.sep.join([covid_dataset_path, 'metadata.csv']), root_dir=covid_dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQh_Hos_3_PD",
        "colab_type": "text"
      },
      "source": [
        "## Creating the data transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtqRM8gM3_PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HistEqualization(object):\n",
        "    \"\"\"Image pre-processing.\n",
        "\n",
        "    Equalize the image historgram\n",
        "    \"\"\"\n",
        "    \n",
        "    def __call__(self,image):\n",
        "        \n",
        "        return ImageOps.equalize(image, mask = None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5aqJtWe3_PG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ContrastBrightness(object):\n",
        "    \"\"\"Image pre-processing.\n",
        "\n",
        "    alpha = 1.0 # Simple contrast control [1.0-3.0]\n",
        "    beta = 0    # Simple brightness control [0-100]\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, alpha, beta):\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "    \n",
        "    def __call__(self,image,):\n",
        "        image = np.array(image)\n",
        "        for y in range(image.shape[0]):\n",
        "            for x in range(image.shape[1]):\n",
        "                image[y,x] = np.clip(self.alpha*image[y,x] + self.beta, 0, 255)\n",
        "\n",
        "                return Image.fromarray(np.uint8(image)*255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTjRjl2K3_PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SmoothImage(object):\n",
        "    \"\"\"Image pre-processing.\n",
        "\n",
        "    Smooth the image\n",
        "    \"\"\"\n",
        "    def __call__(self,image):\n",
        "        \n",
        "        return image.filter(ImageFilter.SMOOTH_MORE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBYZhdJM3_PK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Grayscale(1),\n",
        "        transforms.RandomRotation(30, fill=(0,)),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        ContrastBrightness(1.2,25),\n",
        "        HistEqualization(),\n",
        "        SmoothImage(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5],\n",
        "                             [0.25])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Grayscale(1),\n",
        "        transforms.Resize(240),\n",
        "        transforms.CenterCrop(224),\n",
        "        ContrastBrightness(1.2,25),\n",
        "        HistEqualization(),\n",
        "        SmoothImage(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5],\n",
        "                             [0.25])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0UtI_Kn3_Pa",
        "colab_type": "text"
      },
      "source": [
        "## Create a train, validation and test dataset and the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ORci2MYP8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "850a4d8c-7237-4617-9baf-276bd8b257f9"
      },
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "# Import images as Dataset\n",
        "image_datasets = {\n",
        "    x: image_dataset(\n",
        "        csv_path=os.path.sep.join([covid_dataset_path, 'metadata.csv']),\n",
        "        root_dir=covid_dataset_path,\n",
        "        transform=data_transforms,\n",
        "        phase=x)\n",
        "    for x in ['train', 'test']\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAtaJkOqPT-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Ratio Train -> 70%, Val -> 15%, Test -> 15%\"\"\"\n",
        "total_len = len(image_datasets['train'])\n",
        "\n",
        "# Fractions\n",
        "train_frac = 0.7\n",
        "val_frac = 0.15\n",
        "test_frac = 0.15\n",
        "# Compute number of samples\n",
        "num_train = int(total_len * train_frac)\n",
        "num_val = int(total_len * val_frac)\n",
        "num_test = int(total_len * test_frac)\n",
        "# Indexes \n",
        "indexes = list(range(total_len))\n",
        "# Split training set\n",
        "train_idx = indexes[:num_train]\n",
        "val_idx = indexes[num_train : num_train + num_val]\n",
        "test_idx = indexes[num_train + num_val:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bSC5TTp3_Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create train , val and test dataset and loaders as subset of image dataset\n",
        "train_dataset = Subset(image_datasets['train'], train_idx)\n",
        "val_dataset = Subset(image_datasets['test'], val_idx)\n",
        "test_dataset = Subset(image_datasets['test'], test_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, num_workers=4, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=64, num_workers=4, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, num_workers=4, shuffle=False)\n",
        "\n",
        "loaders = {\"train\": train_loader,\n",
        "           \"val\": val_loader,\n",
        "           \"test\": test_loader}\n",
        "\n",
        "dataset_sizes = {x: len(loaders[x].dataset) for x in ['train', 'val', 'test']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f25ZENvp3_Pd",
        "colab_type": "text"
      },
      "source": [
        "## Create a train method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSHlu93A3_Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, device='cpu'):\n",
        "    \"\"\"\n",
        "    Support function for model training.\n",
        "\n",
        "    Args:\n",
        "      model: Model to be trained\n",
        "      criterion: Optimization criterion (loss)\n",
        "      optimizer: Optimizer to use for training\n",
        "      scheduler: Instance of ``torch.optim.lr_scheduler``\n",
        "      num_epochs: Number of epochs\n",
        "      device: Device to run the training on. Must be 'cpu' or 'cuda'\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    try:\n",
        "      for epoch in range(num_epochs):\n",
        "          print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "          print('-' * 10)\n",
        "\n",
        "          # Each epoch has a training and validation phase\n",
        "          for phase in ['train', 'val', 'test']:\n",
        "              if phase == 'train':\n",
        "                  model.train()  # Set model to training mode\n",
        "              else:\n",
        "                  model.eval()   # Set model to evaluate mode\n",
        "\n",
        "              running_loss = 0.0\n",
        "              running_corrects = 0\n",
        "\n",
        "              # Iterate over data.\n",
        "              for data in loaders[phase]:\n",
        "                  inputs = data['image']\n",
        "                  labels = data['finding']\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  # zero the parameter gradients\n",
        "                  optimizer.zero_grad()\n",
        "                  # forward\n",
        "                  # track history if only in train\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      outputs = model(inputs)\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      # backward + optimize only if in training phase\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "                  # statistics\n",
        "                  running_loss += loss.item() * inputs.size(0)\n",
        "                  running_corrects += torch.sum(preds == labels.data)\n",
        "              if phase == 'train':\n",
        "                  scheduler.step()\n",
        "\n",
        "              epoch_loss = running_loss / dataset_sizes[phase]\n",
        "              epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "              print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                  phase, epoch_loss, epoch_acc))\n",
        "              # deep copy the model\n",
        "              if phase == 'test' and epoch_acc > best_acc:\n",
        "                  best_acc = epoch_acc\n",
        "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    except KeyboardInterrupt:\n",
        "      time_elapsed = time.time() - since\n",
        "      print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "      print('Best validation Acc: {:4f}'.format(best_acc))\n",
        "      # load best model weights\n",
        "      model.load_state_dict(best_model_wts)\n",
        "      return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtFeYFE_3_Pf",
        "colab_type": "text"
      },
      "source": [
        "## CNNs for classification\n",
        "\n",
        "### Case 1 : Pre-trained model fine tuned \"resnet18\"\n",
        "### Case 2 : From scratch model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2in2aj6AQMGH",
        "colab_type": "text"
      },
      "source": [
        "## Case 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GtevlW3_Pf",
        "colab_type": "text"
      },
      "source": [
        "## Load the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuVb0gDX3_Pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(\n",
        "    pretrained=True,\n",
        "    progress=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgMlRXQ03_Pi",
        "colab_type": "text"
      },
      "source": [
        "## Add a front layer to receive the black and white images from the X-Ray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw0bbLyo3_Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFLore-33_Pk",
        "colab_type": "text"
      },
      "source": [
        "## Add a classification layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YRLwF8U3_Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(num_ftrs, num_ftrs),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(num_ftrs, 2),\n",
        ")\n",
        "\n",
        "# Freeze parameters so we don't backprop through them\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3nhuN0m3_Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Note that we are only training the head.\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.1)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUBfLWOh3_Po",
        "colab_type": "text"
      },
      "source": [
        "## Fine tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD7pO91n3_Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = train_model(model.to(device), criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                        num_epochs=50, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Fp5GCRQRN8",
        "colab_type": "text"
      },
      "source": [
        "## Case 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHrGcwrp3_Pq",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxT0zF2l3_Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in dataloaders['test']:\n",
        "        inputs = data['image']\n",
        "        labels = data['finding']\n",
        "        outputs = model_ft(inputs.float().to(device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "print('Accuracy of the network: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEfeF2cT3_Pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in dataloaders['test']:\n",
        "        images = data['image']\n",
        "        labels = data['finding']\n",
        "        outputs = model_ft(images.to(device))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels.to(device)).squeeze()\n",
        "        for i in range(images.shape[0]):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DaHvfNK3_Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=(len(image_datasets['test'])), num_workers=8)\n",
        "\n",
        "dataiter = iter(dataloader)\n",
        "data = dataiter.next()\n",
        "images = data['image']\n",
        "labels = data['finding']\n",
        "\n",
        "model_ft.to('cpu')\n",
        "\n",
        "output = torch.tensor(model_ft(images).detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4peNAsh3_Px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(labels, np.argmax(output,1), target_names=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT__1ZOO3_Pz",
        "colab_type": "code",
        "colab": {},
        "outputId": "e92d5cd6-8625-4396-ab57-ed6e553d8e55"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(labels, np.argmax(output,1))\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 29  25]\n",
            " [  5 136]]\n",
            "acc: 0.8462\n",
            "sensitivity: 0.5370\n",
            "specificity: 0.9645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4SDrx0K3_P1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}